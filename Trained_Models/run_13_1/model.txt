
global test_log =[[],[],[],[],[],[],[]]
global training_log = [[],[],[],[],[],[],[]]

opt = Adam(0.001)
model_name = "run_13_1"
model = Chain(
    #First convolution
    BatchNorm(1),
    Conv((3,3), 1=>16,leakyrelu),
    x-> maxpool(x,(2,2),stride = 2 ),
    #Second convolution 
    Conv((3,3), 16=>16,leakyrelu),
    x-> maxpool(x,(2,2),stride = 2 ),

    #Third convolution 
    Conv((3,3), 16=>16,leakyrelu),
    x-> maxpool(x,(2,2),stride = 2),

    #Fourth convolution
    Conv((3,3), 16=>16,leakyrelu),
    x-> maxpool(x,(2,2),stride = 2 ),

    #Fifth convolution 
    Conv((3,3), 16=>32, leakyrelu),
    #AlphaDropout(0.5),
    Flux.GlobalMeanPool(),
    Flux.flatten,
    
    #Fully connected layer
    Dense(32=>16), 
    Dense(16=>1),
    sigmoid_fast
    #TODO: softmax needs to be added to last dense layer

    )|> gpu 
model=gpu(model)
ps = Flux.params(model)
global best_acc = 0 
loss(x, y) = Flux.Losses.mse(model(x), y)
epochs = 60
#test_model= make_test_batch(H5_Dict,test_data,1)
test_model= make_test_batch(H5_Dict,test_data,1)
#train_model=make_test_batch(H5_Dict,training_data,1)
for i in 1:epochs
    global best_acc
    @info("Epoch: $(i)")
    #if !@isdefined best_acc 
    #    best_acc = 0 
    #    @info("best_acc set to zero")
    #end
    @info("creating training model ...")
    train_model = make_test_batch(H5_Dict, training_data, 1,true, true,true,1)
    @info("training model ...")
    Flux.testmode!(model , false)
    Flux.train!(weighted_loss,ps,train_model,opt)
    Flux.testmode!(model , true)
    @info("training done")

    @info("calculating accuracy loss and f1 score of test set ... ")
    global training_log = f1_score_precission_recall_accuracy(model,training_log, train_model, 1 , false )
    global test_log =f1_score_precission_recall_accuracy(model, test_log, test_model, 1  , true )
    acc = test_log[4][length(test_log[4])]
    if acc >=0.99
        @info(" -> Early-exiting: We reached our target accuracy of 99.9%")
        break
    end
    if acc >= best_acc
        @info(" -> New best accuracy! Saving model out to mnist_conv.bson")
        if !isdir(model_name)
            mkdir(model_name)
        end
        BSON.@save "$(model_name)\\epoch_$(i)_acc_$(acc).bson" model
        best_acc = acc 
    
    end
    #weight decay ...
    #opt.eta = opt.eta*0.94 #for Adam
    #opt.os[1].eta = opt.os[1].eta*0.89 # 0.94 is if we want a * 0.3 every 20 epochs atm its *0.3 every 10 epochs 
end 

save_models(test_log,training_log)


JLD2.save_object("$(model_name)\\traininglog_epoch_model_$(model_name)_best_acc_$(best_acc).jld2",test_log)

